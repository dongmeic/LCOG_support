{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b047a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from homeless import *\n",
    "import openpyxl\n",
    "from win32com.client import Dispatch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727a4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = r'G:\\projects\\UtilityDistricts\\eweb\\DrinkingWater\\IllegalCampCoordination\\Recieved'\n",
    "path = outpath + '\\\\IllegalCampNotification_pro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8509b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_excel(path+'\\\\most_recent.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595d1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2drop = ['OBJECTID', 'Join_Count', 'Unruly_inhabitants']\n",
    "dat = dat.drop(cols2drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7512183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.columns = list(map(lambda x: x.capitalize(), dat.columns))\n",
    "dat.rename(columns={'Ownname': 'Owner_name', 'Addr1': 'Owner_address'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b18f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Nearby_owner' in dat.columns:\n",
    "    k = 2\n",
    "    dat = dat[['Target_fid', 'Status', 'Comments', 'Date', 'Submitted_by','Dogs_present', 'Hazardous_materials_present', \n",
    "    'Biohazards_present','Size_of_encampment', 'Maptaxlot_hyphen', 'Owner_name', 'Owner_address', 'Nearby_owner', \n",
    "    'Nearby_owner_address', 'Ownercity', 'Ownerprvst', 'Ownerzip', 'Geocity_name', 'Ugb_name','Longitude', 'Latitude']]\n",
    "    taxlotcodes = pd.read_csv('mythical_taxlot_codes.csv')\n",
    "    for idx in range(0, dat.shape[0]):\n",
    "        taxlotcode = int(dat.loc[idx,'Maptaxlot_hyphen'][-2:])\n",
    "        if (str(dat.loc[idx, 'Owner_name']) == 'nan') & (taxlotcode in taxlotcodes.end_number.values):\n",
    "            dat.loc[idx, 'Owner_name'] = taxlotcodes.loc[taxlotcodes.end_number == taxlotcode, 'taxlot'].values[0].capitalize() + ' R/W'\n",
    "else:\n",
    "    k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d79ac735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.rename(columns={'Target_fid': 'Target_FID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78fab41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data...\n"
     ]
    }
   ],
   "source": [
    "intakepath = r'G:\\projects\\UtilityDistricts\\eweb\\DrinkingWater\\RiparianEcosystemMarketplace\\market_area\\REM_area.gdb'\n",
    "intake_areas = gpd.read_file(intakepath, driver='FileGDB', layer='AboveIntake')\n",
    "points = gpd.read_file(path + '\\\\MyProject4.gdb', driver='FileGDB', layer='HomelessCampSite_SpatialJoin')\n",
    "points = points.to_crs(epsg=2914)\n",
    "print(\"Read data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a904fc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got file name...\n"
     ]
    }
   ],
   "source": [
    "urlstart ='https://services5.arcgis.com/9s1YtFmLS0YTl10F/arcgis/rest/services/ZHomeless_Camp_Trash_Collector/FeatureServer/0/'\n",
    "urlend = '/attachments?f=html&token='\n",
    "\n",
    "datestr = points.Date.values[0].split('T')[0]\n",
    "res = convert_date(datestr)\n",
    "Y = res[1]\n",
    "m = res[2]\n",
    "d = res[3]\n",
    "outfolder = os.path.join(outpath, Y, m+'_'+d)\n",
    "filename = 'IllegalCampNotice_'+m+'_'+d+'_'+Y[2:4]+'.xlsx'\n",
    "file = os.path.join(outfolder, filename)\n",
    "print(\"Got file name...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687ef5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clid1852\\AppData\\Anaconda3\\envs\\geoenv\\lib\\site-packages\\geopandas\\base.py:31: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\Users\\clid1852\\AppData\\Anaconda3\\envs\\geoenv\\lib\\site-packages\\geopandas\\base.py:31: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\Users\\clid1852\\AppData\\Anaconda3\\envs\\geoenv\\lib\\site-packages\\geopandas\\base.py:31: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n",
      "C:\\Users\\clid1852\\AppData\\Anaconda3\\envs\\geoenv\\lib\\site-packages\\geopandas\\base.py:31: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edited data...\n"
     ]
    }
   ],
   "source": [
    "for pID in points.index:\n",
    "    point = points[points.index==pID]\n",
    "    if all(intake_areas.contains(point)):\n",
    "        dat.loc[pID, 'Above_Intake'] = 'Yes'\n",
    "    else:\n",
    "        dat.loc[pID, 'Above_Intake'] = 'No'\n",
    "    FID = dat.loc[pID, 'Target_FID']\n",
    "    url= urlstart+str(FID)+urlend\n",
    "    resp=requests.get(url)\n",
    "    links = []\n",
    "    if resp.status_code==200:\n",
    "        soup=BeautifulSoup(resp.text,'html.parser')\n",
    "        for link in soup.findAll('a'):\n",
    "            links.append(link.get('href'))\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    attached = [link for link in links if 'attachments' in link]\n",
    "    if len(attached)==0:\n",
    "        dat.loc[pID, 'Photos'] = 'NA'\n",
    "    elif len(attached)==1:\n",
    "        dat.loc[pID, 'Photos'] = 'https://services5.arcgis.com' + attached[0]\n",
    "    else:\n",
    "        dat.loc[pID, 'Photos'] = '; '.join(['https://services5.arcgis.com' + s for s in attached])\n",
    "\n",
    "print(\"Edited data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e011b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported data...\n"
     ]
    }
   ],
   "source": [
    "dat.loc[:, 'Date'] = dat.Date.astype(str)\n",
    "dat.to_excel(file, index=False)\n",
    "print(\"Exported data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "969a3967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked photos...\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_excel(file)\n",
    "wb = openpyxl.load_workbook(file)\n",
    "ws = wb.active\n",
    "ws = removeFormatting(ws)\n",
    "for pID in points.index:\n",
    "    photovalue = dat.loc[pID, 'Photos']\n",
    "    if str(photovalue) == 'nan':\n",
    "        print(f\"No photos at Point {dat.loc[pID, 'Target_FID']}\")\n",
    "    else:\n",
    "        ws.cell(row=2+pID, column=21+k).value = 'Yes'\n",
    "        if ';' in photovalue: \n",
    "            urls = photovalue.split('; ')\n",
    "            for i in range(0, len(urls)):\n",
    "                ws.cell(row=2+pID, column=22+i+k).value = '=HYPERLINK(\"{}\", \"{}\")'.format(urls[i],'Photo '+str(i+1))\n",
    "                ws.cell(row=2+pID, column=22+i+k).style = \"Hyperlink\"\n",
    "        else:\n",
    "            ws.cell(row=2+pID, column=22+k).value = '=HYPERLINK(\"{}\", \"{}\")'.format(photovalue,'Photo')\n",
    "            ws.cell(row=2+pID, column=22+k).style = \"Hyperlink\"\n",
    "wb.save(file)\n",
    "print(\"Checked photos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e23f8ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autofitted columns...\n"
     ]
    }
   ],
   "source": [
    "excel = Dispatch('Excel.Application')\n",
    "wb = excel.Workbooks.Open(file)\n",
    "excel.Worksheets(1).Activate()\n",
    "excel.ActiveSheet.Columns.AutoFit()\n",
    "wb.Close(True)\n",
    "print(\"Autofitted columns...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
